{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-_u6z_StwjqE"
   },
   "source": [
    "__Tutorial for CUDA programming using Python__\n",
    "==================================================\n",
    "\n",
    "## Reduction\n",
    "\n",
    "In computer science, the __reduction__ operator is a type of operator that is commonly used in parallel programming to reduce the elements of an array into a single result. \n",
    "\n",
    "+ vector norm\n",
    "+ dot product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nX8jA1XXwjqG"
   },
   "outputs": [],
   "source": [
    "# if you are using colab\n",
    "# !pip install pycuda # pycuda installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "po4UQeXIwjqH"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# --- PyCUDA initialization\n",
    "import pycuda\n",
    "import pycuda.gpuarray as gpuarray\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "from pycuda.compiler import SourceModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T9Oh_lImwjqH"
   },
   "outputs": [],
   "source": [
    "def nextpow2(x):  \n",
    "    return 1 if x == 0 else 2**(x - 1).bit_length()\n",
    "\n",
    "def getThreadsAndBlocks(kerId, num, maxBlocks, maxThreads):\n",
    "    if kerId < 3:\n",
    "        threads = nextpow2(num) if num < maxThreads else maxThreads\n",
    "        blocks = int((num + threads - 1) / threads)\n",
    "    else:\n",
    "        threads = nextpow2(int((num+1)/2)) if num < maxThreads else maxThreads \n",
    "        blocks = int((num + 2*2*threads -1) / (2*threads))\n",
    "    \n",
    "    if kerId == 6:\n",
    "        blocks = blocks if maxBlocks > blocks else maxBlocks\n",
    "\n",
    "    return threads, blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z6v2Z6L-wjqI"
   },
   "outputs": [],
   "source": [
    "src_prKer1 = \"\"\"\n",
    "\n",
    "__global__ void product_reduction1(double* p, double*q, double*c, int NUM)\n",
    "{\n",
    "    extern __shared__ double sdata[];\n",
    "\n",
    "    // load shared mem\n",
    "    unsigned int tid = threadIdx.x;\n",
    "    unsigned int i = blockIdx.x*blockDim.x + threadIdx.x;\n",
    "\n",
    "    sdata[tid] = (i < NUM) ? p[i]*q[i] : 0;\n",
    "\n",
    "    __syncthreads();\n",
    "\n",
    "    // do reduction in shared mem\n",
    "    for (unsigned int s=1; s < blockDim.x; s *= 2)\n",
    "    {\n",
    "        // modulo arithmetic is slow!\n",
    "        if ((tid % (2*s)) == 0)\n",
    "        {\n",
    "            sdata[tid] += sdata[tid + s];\n",
    "        }\n",
    "\n",
    "        __syncthreads();\n",
    "    }\n",
    "\n",
    "    // write result for this block to global mem\n",
    "    if (tid == 0) c[blockIdx.x] = sdata[0];\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "91RE50diwjqI"
   },
   "outputs": [],
   "source": [
    "src_prKer6 = \"\"\"\n",
    "\n",
    "__global__ void product_reduction6(double* p, double*q, double*c, int NUM)\n",
    "{\n",
    "    unsigned int threadsPerBlocks = 512;\n",
    "    bool numIsPow2 = true;\n",
    "    extern __shared__ double sdata[];\n",
    "\n",
    "    unsigned int tid = threadIdx.x;\n",
    "    unsigned int idx = blockIdx.x*threadsPerBlocks*2 + threadIdx.x;\n",
    "    unsigned int gridSize = threadsPerBlocks*2*gridDim.x;\n",
    "\n",
    "    double temp = (double) 0;\n",
    "    while(idx<NUM)\n",
    "    {\n",
    "        temp += (p[idx]*q[idx]);\n",
    "        if(numIsPow2 || idx + threadsPerBlocks < NUM)\n",
    "            temp += (p[idx+threadsPerBlocks]*q[idx+threadsPerBlocks]);\n",
    "        idx += gridSize;\n",
    "    }\n",
    "\n",
    "    sdata[tid] = temp;\n",
    "    __syncthreads();\n",
    "\n",
    "    if(threadsPerBlocks>=512){if (tid<256) {sdata[tid] = temp = temp + sdata[tid+256];} __syncthreads();}\t\n",
    "    if(threadsPerBlocks>=256){if (tid<128) {sdata[tid] = temp = temp + sdata[tid+128];} __syncthreads();}\t\n",
    "    if(threadsPerBlocks>=128){if (tid< 64) {sdata[tid] = temp = temp + sdata[tid+ 64];} __syncthreads();}\n",
    "\n",
    "    if(tid<32)\n",
    "    {\n",
    "        volatile double* smem = sdata;\n",
    "        if(threadsPerBlocks >= 64){ smem[tid] = temp = temp + smem[tid+32];}\n",
    "        if(threadsPerBlocks >= 32){ smem[tid] = temp = temp + smem[tid+16];}\n",
    "        if(threadsPerBlocks >= 16){ smem[tid] = temp = temp + smem[tid+ 8];}\n",
    "        if(threadsPerBlocks >=  8){ smem[tid] = temp = temp + smem[tid+ 4];}\n",
    "        if(threadsPerBlocks >=  4){ smem[tid] = temp = temp + smem[tid+ 2];}\n",
    "        if(threadsPerBlocks >=  2){ smem[tid] = temp = temp + smem[tid+ 1];}\n",
    "    }\n",
    "\n",
    "    if(tid==0)\n",
    "        c[blockIdx.x] = sdata[0];\n",
    "}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YS3J0VMfwjqJ",
    "outputId": "5023ddb9-e825-45b3-b96f-f8badb7eb5f3"
   },
   "outputs": [],
   "source": [
    "# e_start = pycuda.driver.Event()\n",
    "# e_stop = pycuda.driver.Event()\n",
    "\n",
    "N = 2**27\n",
    "\n",
    "# thread, blocks, shared memory size\n",
    "threads, blocks = getThreadsAndBlocks(1, N, 64, 512)\n",
    "\n",
    "smems = 2*threads*8 if threads <= 32 else threads*8\n",
    "print(threads, blocks, smems)\n",
    "\n",
    "# block and grid dimensions\n",
    "blockDim  = (threads, 1, 1)\n",
    "gridDim   = (blocks, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3CJMX-IiwjqJ"
   },
   "outputs": [],
   "source": [
    "h_a = np.random.uniform(-1, 1, size=N).astype(np.float64)\n",
    "h_b = np.random.uniform(-1, 1, size=N).astype(np.float64)\n",
    "h_cache = np.zeros(blocks).astype(np.float64) \n",
    "\n",
    "# copy to device\n",
    "d_a = pycuda.gpuarray.to_gpu(h_a)\n",
    "d_b = pycuda.gpuarray.to_gpu(h_b)\n",
    "d_cache = pycuda.gpuarray.zeros(blocks, dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zRUn6Wv9wjqJ",
    "outputId": "02b25c3f-b136-4bc5-a6ad-23fad88536c2"
   },
   "outputs": [],
   "source": [
    "# cuda compile ...\n",
    "\n",
    "print('kernel build')\n",
    "module_ker1 = pycuda.compiler.SourceModule(source=src_prKer1)\n",
    "# \n",
    "dev_dot_ker1 = module_ker1.get_function(\"product_reduction1\")\n",
    "\n",
    "##\n",
    "module_ker6 = pycuda.compiler.SourceModule(source=src_prKer6)\n",
    "# \n",
    "dev_dot_ker6 = module_ker6.get_function(\"product_reduction6\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AfQLkerdxSla",
    "outputId": "74b4e7b3-fef0-4e0a-b9df-655aa3b4d15d"
   },
   "outputs": [],
   "source": [
    "# e_start.record()\n",
    "print('reduction : gpu kernel 1')\n",
    "\n",
    "dev_dot_ker1(d_a, d_b, d_cache, np.int32(N), block=blockDim, grid=gridDim, shared=smems)\n",
    "\n",
    "t_start = time.time()\n",
    "\n",
    "dev_dot_ker1(d_a, d_b, d_cache, np.int32(N), block=blockDim, grid=gridDim, shared=smems)\n",
    "h_cache = d_cache.get()\n",
    "c_ = np.sum(h_cache)\n",
    "\n",
    "elapsed = time.time() - t_start\n",
    "\n",
    "pycuda.driver.Context.synchronize()\n",
    "\n",
    "print(c_)\n",
    "print(\"Processing time = {:f}\".format(elapsed))\n",
    "\n",
    "print(\"#\"*64)\n",
    "\n",
    "print('reduction : gpu kernel 6')\n",
    "\n",
    "# temp\n",
    "dev_dot_ker6(d_a, d_b, d_cache, np.int32(N), block=blockDim, grid=gridDim, shared=smems)\n",
    "\n",
    "t_start = time.time()\n",
    "\n",
    "dev_dot_ker6(d_a, d_b, d_cache, np.int32(N), block=blockDim, grid=gridDim, shared=smems)\n",
    "h_cache = d_cache.get()\n",
    "c_ = np.sum(h_cache)\n",
    "\n",
    "elapsed = time.time() - t_start\n",
    "\n",
    "pycuda.driver.Context.synchronize()\n",
    "\n",
    "print(c_)\n",
    "print(\"Processing time = {:f}\".format(elapsed))\n",
    "\n",
    "\n",
    "print(\"#\"*64)\n",
    "\n",
    "# print('reduction : gpuarray dot')\n",
    "# t_start = time.time()\n",
    "# d_c = pycuda.gpuarray.vdot(d_a, d_b)\n",
    "# elapsed = time.time() - t_start\n",
    "# c_ = d_c.get()\n",
    "# pycuda.driver.Context.synchronize()\n",
    "\n",
    "# print(c_)\n",
    "\n",
    "# print(\"Processing time = {:f}\".format(elapsed))\n",
    "\n",
    "# print(\"#\"*64)\n",
    "\n",
    "print('reduction : cpu')\n",
    "t_start = time.time()\n",
    "c_= np.dot(h_a, h_b)\n",
    "elapsed = time.time() - t_start\n",
    "\n",
    "print(c_)\n",
    "#secs = e_start.time_till(e_stop) * 1e-3\n",
    "print(\"Processing time = {:f}\".format(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"#\"*64)\n",
    "\n",
    "print('reduction : pycuda gpuarray dot')\n",
    "\n",
    "d_c = pycuda.gpuarray.dot(d_a, d_b)\n",
    "\n",
    "t_start = time.time()\n",
    "d_c = pycuda.gpuarray.dot(d_a, d_b)\n",
    "c_ = d_c.get()\n",
    "elapsed = time.time() - t_start\n",
    "\n",
    "pycuda.driver.Context.synchronize()\n",
    "print(c_)\n",
    "\n",
    "# secs = e_start.time_till(e_stop) * 1e-3\n",
    "print(\"Processing time = {:f}\".format(elapsed))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "07_cuda_reduction.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
